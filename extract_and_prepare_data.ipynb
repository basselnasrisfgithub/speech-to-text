{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**split audio by detecting the sound**"
      ],
      "metadata": {
        "id": "9P0Ki8kvMt05"
      },
      "id": "9P0Ki8kvMt05"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bd071b8",
      "metadata": {
        "id": "3bd071b8"
      },
      "outputs": [],
      "source": [
        "from os import path\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr \n",
        "import os \n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "A=0\n",
        "def get_large_audio_transcription(path,silence=500):\n",
        "    \"\"\"\n",
        "    Splitting the large audio file into chunks\n",
        "    and apply speech recognition on each of these chunks\n",
        "    \"\"\"\n",
        "    # open the audio file using pydub\n",
        "    sound = AudioSegment.from_wav(path)  \n",
        "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
        "    \n",
        "    chunks = split_on_silence(\n",
        "    sound,\n",
        "\n",
        "    # split on silences longer than 1000ms (1 sec)\n",
        "    min_silence_len=600,\n",
        "\n",
        "    # anything under -16 dBFS is considered silence\n",
        "    silence_thresh = sound.dBFS-14,      \n",
        "\n",
        "    )\n",
        "\n",
        "    # now recombine the chunks so that the parts are at least 90 sec long\n",
        "    \n",
        "    folder_name = 'voices'\n",
        "        # create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name):\n",
        "            os.mkdir(folder_name)\n",
        "    # process each chunk \n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "        # export audio chunk and save it in\n",
        "        # the `folder_name` directory.\n",
        "        chunk_filename = os.path.join(folder_name, f\"{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "#         A+=1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**load videos downloaded**"
      ],
      "metadata": {
        "id": "OcpAKkVZNHo5"
      },
      "id": "OcpAKkVZNHo5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d81339b",
      "metadata": {
        "id": "0d81339b"
      },
      "outputs": [],
      "source": [
        "import wave\n",
        "import contextlib\n",
        "import os\n",
        "#hone enta lezim tnazil videos online, ykoune type .wav  w t7oton bi folder 2esmo videos\n",
        "directory='./videos/'\n",
        "voices=os.listdir(directory)\n",
        "\n",
        "for voice in voices:\n",
        "       get_large_audio_transcription(source+str(voice),silence=500)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove voices where duration is more than specific number of seconds"
      ],
      "metadata": {
        "id": "cRUHu7XlNR-8"
      },
      "id": "cRUHu7XlNR-8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c1c6b27",
      "metadata": {
        "id": "1c1c6b27"
      },
      "outputs": [],
      "source": [
        "#calcul of duration and remove voice\n",
        "import wave\n",
        "import contextlib\n",
        "voices houwe lfolder li b2albo lvoices splitted\n",
        "source='./voices/'\n",
        "voices=os.listdir(source)\n",
        "\n",
        "\n",
        "for voice in voices:\n",
        "      with contextlib.closing(wave.open(source+str(voice),'r')) as f:\n",
        "            frames = f.getnframes()\n",
        "            rate = f.getframerate()\n",
        "            duration = frames / float(rate)\n",
        "            f.close()\n",
        "            if (duration<4 or duration >=9 ):    \n",
        "                  os.remove(source+str(voice))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extract specific duration from an audio**"
      ],
      "metadata": {
        "id": "tRuUIE3RNoQu"
      },
      "id": "tRuUIE3RNoQu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "963c5dd6",
      "metadata": {
        "id": "963c5dd6"
      },
      "outputs": [],
      "source": [
        "def cut_voice(path_to_file,remove=True):\n",
        "    \n",
        "    # Import part 1 audio file\n",
        "    part_1 = AudioSegment.from_file(path_to_file)\n",
        "    # Remove the first four seconds of part 1\n",
        "    part_1_removed = part_1[:11000]\n",
        "    filename = os.path.join('./voice-trim', f\"{10}.wav\")\n",
        "    part_1_removed.export(filename, format=\"wav\")\n",
        "    os.remove(file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**sorting the folder is necessary if the names of audio files are '1.wav', '2.wav', 3ashain 2eza enta mra2emon hek w keib transcript taba3on bel dor bi excel file, momken bas ta3melon load 7a yen3amalon sorting 8er.**"
      ],
      "metadata": {
        "id": "uxrBIInwOSvs"
      },
      "id": "uxrBIInwOSvs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2183e82",
      "metadata": {
        "id": "e2183e82"
      },
      "outputs": [],
      "source": [
        "# take second element for sort\n",
        "def sorting(elem):\n",
        "    return int(elem[:len(elem)-4])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename files in a folder"
      ],
      "metadata": {
        "id": "H_aTsQYdObzT"
      },
      "id": "H_aTsQYdObzT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0258582",
      "metadata": {
        "id": "c0258582"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path='./voices/'\n",
        "voices=os.listdir(path)\n",
        "voices.sort(key=sorting)\n",
        "\n",
        "\n",
        "for voice in voices :\n",
        "    old_name = path+str(voice)\n",
        "    os.rename(old_name,'./voices/'+str(L)+'.wav')\n",
        "    L+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to load model from hugging face**\n"
      ],
      "metadata": {
        "id": "-qvyXwtZOlS7"
      },
      "id": "-qvyXwtZOlS7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "633538f8",
      "metadata": {
        "id": "633538f8"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCTC, Wav2Vec2Processor\n",
        "\n",
        "model = AutoModelForCTC.from_pretrained('ali-issa/wav2vec2-Arabizi-gpu-colab-similar-to-german-param')\n",
        "processor = Wav2Vec2Processor.from_pretrained('ali-issa/wav2vec2-Arabizi-gpu-colab-similar-to-german-param')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f972d798",
      "metadata": {
        "id": "f972d798"
      },
      "outputs": [],
      "source": [
        "def predict(samples) :\n",
        "  inputs = processor(samples,return_tensors=\"pt\",sampling_rate=16000 ,padding=True)\n",
        "  logits = model(inputs.input_values).logits\n",
        "  pred_ids = torch.argmax(logits, dim=-1)[0]\n",
        "  predicted=processor.decode(pred_ids)\n",
        "  return predicted\n",
        "L=0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1)sta5dim lmodel li 3melnelo load w fawit l voices ka input 3le w 7ot louput li houwe transcript b2aleb excel file\n",
        "\n",
        "2) Kamen na3melon load lal voices w nesta5dim API google kermel yotla3lna transcript men API google\n"
      ],
      "metadata": {
        "id": "hpyw7D96O6V-"
      },
      "id": "hpyw7D96O6V-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ad6493c",
      "metadata": {
        "scrolled": false,
        "id": "6ad6493c"
      },
      "outputs": [],
      "source": [
        "import xlwt\n",
        "from xlwt import Workbook\n",
        "import librosa\n",
        "import torch\n",
        "# Workbook is created\n",
        "wb = Workbook()\n",
        "# L hiye 3ibara 3an lrow li badna nektoub fiya lexcel file\n",
        "L=0\n",
        "\n",
        "# add_sheet is used to create sheet.\n",
        "sheet1 = wb.add_sheet('Sheet 1')\n",
        "import speech_recognition as sr\n",
        "import os\n",
        "from shutil import copyfile\n",
        "\n",
        "r = sr.Recognizer()\n",
        "directory='./voices/'\n",
        "voices=os.listdir(directory)\n",
        "voices.sort(key=sorting)\n",
        "\n",
        "# eza badna nesta5dim google api\n",
        "for voice in voices :\n",
        "    with sr.AudioFile(directory+str(voice)) as source:\n",
        "                    audio_data = r.record(source)\n",
        "                    text = r.recognize_google(audio_data,language='ar-LB')\n",
        "                    sheet1.write(L,0,text)\n",
        "                    print(L)\n",
        "                    L+=1  \n",
        "                    # save an excel file\n",
        "                    wb.save('transcript.xls')\n",
        "\n",
        "# eza badna nesta5dim l`model loaded from wav2vec \n",
        "for voice in voices :\n",
        "                    samples, sample_rate = librosa.load(directory+str(voice),sr=16000)\n",
        "                    # predict function li 5ala2neha fo2\n",
        "                    text=predict(samples)\n",
        "                    print(L)\n",
        "                    sheet1.write(L,0,text)\n",
        "                    L+=1   \n",
        "                    # save an excel file\n",
        "                    wb.save('transcript.xls')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Steps to Create the data set**"
      ],
      "metadata": {
        "id": "g3vLWhgySzE_"
      },
      "id": "g3vLWhgySzE_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1-load files as one dimensional array using librosa**"
      ],
      "metadata": {
        "id": "ZrqAzJTiS_j8"
      },
      "id": "ZrqAzJTiS_j8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7db518c",
      "metadata": {
        "id": "e7db518c"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy\n",
        "samples=[]\n",
        "rate=[]\n",
        "directory='./voices/'\n",
        "voices=os.listdir(directory)\n",
        "voices.sort(key=sorting)\n",
        "\n",
        "for voice in voices :\n",
        "    sample,sr=librosa.load('./voices/'+str(voice[:]),sr=16000)\n",
        "    samples.append(sample)\n",
        "    rate.append(sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2-read the corresoinding transcript of each voices**"
      ],
      "metadata": {
        "id": "WvMgRM5OS7VV"
      },
      "id": "WvMgRM5OS7VV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a306966",
      "metadata": {
        "id": "1a306966"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "file_loc = \"./transcript.xls\"\n",
        " \n",
        "sheet1=None\n",
        "with pd.ExcelFile(file_loc) as reader:\n",
        "    sheet1 = pd.read_excel(reader, sheet_name='Sheet 2')\n",
        "Text=[]\n",
        "for e in sheet1['Arabizi']:\n",
        "    Text.append(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**create train set,7atet 2000 3ashain dataset 7aliyan 2100, fa be5oud 2000 menon lal training**"
      ],
      "metadata": {
        "id": "eTyNXfr-Tb98"
      },
      "id": "eTyNXfr-Tb98"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232942ae",
      "metadata": {
        "id": "232942ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.DataFrame(\n",
        "   {\n",
        "       'audio':voices[:2000],\n",
        "       'samples':samples[:2000],\n",
        "       'sample_rate':rate[:2000],\n",
        "       'text':Text[:2000],\n",
        "   }\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**save l data bi path m3ayan**"
      ],
      "metadata": {
        "id": "LDE-C3lyVKGl"
      },
      "id": "LDE-C3lyVKGl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1216d787",
      "metadata": {
        "id": "1216d787"
      },
      "outputs": [],
      "source": [
        "df.to_json(r'C:\\Users\\Ali\\Desktop\\FYP\\prepare_data_set\\arabizi_train_set.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**nafes l procedure for dev set**"
      ],
      "metadata": {
        "id": "jOpms-4hVWyV"
      },
      "id": "jOpms-4hVWyV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfe9f2b8",
      "metadata": {
        "id": "bfe9f2b8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df=pd.DataFrame(\n",
        "   {\n",
        "       'audio':voices[2000:],\n",
        "       'samples':samples[2000:],\n",
        "       'sample_rate':rate[2000:],\n",
        "       'text':Text[2000:],\n",
        "   }\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9499e68e",
      "metadata": {
        "id": "9499e68e"
      },
      "outputs": [],
      "source": [
        "df.to_json(r'C:\\Users\\Ali\\Desktop\\FYP\\prepare_data_set\\arabizi_test_set.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ne7soub 3adad se3at lmawjoud bel folder li b2albo l voices**"
      ],
      "metadata": {
        "id": "5EzGKQu_ViCW"
      },
      "id": "5EzGKQu_ViCW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fecbee4d",
      "metadata": {
        "id": "fecbee4d"
      },
      "outputs": [],
      "source": [
        "#calcul of duration and remove voice\n",
        "import wave\n",
        "import contextlib\n",
        "import os\n",
        "source='./part-1/'\n",
        "voices=os.listdir(source)\n",
        "voices.sort(key=sorting)\n",
        "liste=[]\n",
        "\n",
        "for voice in voices:\n",
        "      with contextlib.closing(wave.open(source+str(voice),'r')) as f:\n",
        "            frames = f.getnframes()\n",
        "            rate = f.getframerate()\n",
        "            duration = frames / float(rate)\n",
        "            liste.append(duration)\n",
        "            f.close()\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b7c7e66",
      "metadata": {
        "id": "3b7c7e66"
      },
      "outputs": [],
      "source": [
        "x=0\n",
        "for elem in liste:\n",
        "    x+=elem\n",
        "# printing total value\n",
        "print(\"number of hours: \", x/3600)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "extract_and_prepare_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}