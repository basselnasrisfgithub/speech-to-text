{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sp_diarization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3afanqemkK3H"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOWfG0Vs0KZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c640e1-c9bc-4002-8890-acbf0a3c701b"
      },
      "source": [
        "#For Installing pyannote from github properly run this and the cell next to this.\n",
        "#Then Restart the runtime and again run both the cells to avoid further errors.\n",
        "# !pip install typing-extensions==3.7.4.1\n",
        "!pip install h5py==2.10.0"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install typing-extensions --upgrade"
      ],
      "metadata": {
        "id": "K9ot0NWTpBev",
        "outputId": "b30860f8-4528-4bc2-9415-24d8f014c321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (4.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyannote.audio==1.1.1"
      ],
      "metadata": {
        "id": "LMCYAslJn6SU",
        "outputId": "b4cabb36-a8d0-42bf-8f34-abe8102cdec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyannote.audio==1.1.1 in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (2.4.0)\n",
            "Requirement already satisfied: pyannote.metrics>=2.3 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (3.2)\n",
            "Requirement already satisfied: tensorboard>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (2.8.0)\n",
            "Requirement already satisfied: Pillow>=6.2.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (4.2.0)\n",
            "Requirement already satisfied: sortedcollections>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (2.1.0)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (4.64.0)\n",
            "Requirement already satisfied: pyannote.database>=4.0 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (4.1.3)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (4.2.4)\n",
            "Requirement already satisfied: pescador>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (2.1.0)\n",
            "Requirement already satisfied: pyannote.pipeline<2.0.0,>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (1.5.2)\n",
            "Requirement already satisfied: pyYAML>=3.12 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (0.10.3.post1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (1.0.2)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (0.8.1)\n",
            "Requirement already satisfied: pyannote.core>=4.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (4.4)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyannote.audio==1.1.1) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->pyannote.audio==1.1.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->pyannote.audio==1.1.1) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->pyannote.audio==1.1.1) (0.51.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->pyannote.audio==1.1.1) (1.21.6)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->pyannote.audio==1.1.1) (0.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->pyannote.audio==1.1.1) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->pyannote.audio==1.1.1) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->pyannote.audio==1.1.1) (21.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->pyannote.audio==1.1.1) (2.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->pyannote.audio==1.1.1) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->pyannote.audio==1.1.1) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.8.0->pyannote.audio==1.1.1) (3.0.8)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyannote.audio==1.1.1) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.18.0->pyannote.audio==1.1.1) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=15.0 in /usr/local/lib/python3.7/dist-packages (from pescador>=2.1.0->pyannote.audio==1.1.1) (22.3.0)\n",
            "Requirement already satisfied: six>=1.8 in /usr/local/lib/python3.7/dist-packages (from pescador>=2.1.0->pyannote.audio==1.1.1) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->pyannote.audio==1.1.1) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->pyannote.audio==1.1.1) (1.4.4)\n",
            "Requirement already satisfied: simplejson>=3.8.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.core>=4.1->pyannote.audio==1.1.1) (3.17.6)\n",
            "Requirement already satisfied: typer[all]>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.database>=4.0->pyannote.audio==1.1.1) (0.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics>=2.3->pyannote.audio==1.1.1) (3.2.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics>=2.3->pyannote.audio==1.1.1) (0.6.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics>=2.3->pyannote.audio==1.1.1) (0.8.9)\n",
            "Requirement already satisfied: sympy>=1.1 in /usr/local/lib/python3.7/dist-packages (from pyannote.metrics>=2.3->pyannote.audio==1.1.1) (1.7.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=2.3->pyannote.audio==1.1.1) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=2.3->pyannote.audio==1.1.1) (0.11.0)\n",
            "Requirement already satisfied: filelock>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (3.6.0)\n",
            "Requirement already satisfied: optuna>=1.4 in /usr/local/lib/python3.7/dist-packages (from pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (2.10.0)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (3.10.1)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (1.7.7)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (1.4.36)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (0.8.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (6.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->pyannote.audio==1.1.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->pyannote.audio==1.1.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->pyannote.audio==1.1.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa>=0.8.0->pyannote.audio==1.1.1) (2021.10.8)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.2->pyannote.audio==1.1.1) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->pyannote.audio==1.1.1) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->pyannote.audio==1.1.1) (2.21)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (4.11.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy>=1.1->pyannote.metrics>=2.3->pyannote.audio==1.1.1) (1.2.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (0.6.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (1.44.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.0.0->pyannote.audio==1.1.1) (3.17.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0.0->pyannote.audio==1.1.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.0.0->pyannote.audio==1.1.1) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.0.0->pyannote.audio==1.1.1) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.0.0->pyannote.audio==1.1.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.0.0->pyannote.audio==1.1.1) (3.2.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer[all]>=0.2.1->pyannote.database>=4.0->pyannote.audio==1.1.1) (7.1.2)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from typer[all]>=0.2.1->pyannote.database>=4.0->pyannote.audio==1.1.1) (1.4.0)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from typer[all]>=0.2.1->pyannote.database>=4.0->pyannote.audio==1.1.1) (0.4.4)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (1.2.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (5.7.1)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (2.4.1)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (0.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (5.9.0)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (3.2.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (3.5.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (0.2.5)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (1.8.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (21.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna>=1.4->pyannote.pipeline<2.0.0,>=1.5.2->pyannote.audio==1.1.1) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS6dRr5d0SQv"
      },
      "source": [
        "# !pip install -q https://github.com/pyannote/pyannote-audio/tarball/develop"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/muskang48/Speaker-Diarization.git"
      ],
      "metadata": {
        "id": "02chzwBVkqfF",
        "outputId": "a58998e0-fe40-4a9f-a526-25e2865c6083",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Speaker-Diarization' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5CcYZOLkfhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ecd82d4-5608-420d-afc7-322016e682a7"
      },
      "source": [
        "#Voice Activity Detection\n",
        "!pip install webrtcvad\n",
        "import contextlib\n",
        "import numpy as np\n",
        "import wave\n",
        "import librosa\n",
        "import webrtcvad\n",
        "\n",
        "\n",
        "def read_wave(path):\n",
        "    with contextlib.closing(wave.open(path, 'rb')) as wf:\n",
        "        num_channels = wf.getnchannels()\n",
        "        assert num_channels == 1\n",
        "        sample_width = wf.getsampwidth()\n",
        "        assert sample_width == 2\n",
        "        sample_rate = wf.getframerate()\n",
        "        print(\"sample_rate = \",sample_rate)\n",
        "        assert sample_rate in (8000, 16000, 32000, 8000)\n",
        "        pcm_data = wf.readframes(wf.getnframes())\n",
        "        return pcm_data, sample_rate\n",
        "\n",
        "\n",
        "class Frame(object):\n",
        "  def __init__(self, bytes, timestamp, duration):\n",
        "        self.bytes = bytes\n",
        "        self.timestamp = timestamp\n",
        "        self.duration = duration\n",
        "\n",
        "\n",
        "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
        "    n = int(sample_rate * (frame_duration_ms / 1000.0) * 2)\n",
        "    offset = 0\n",
        "    timestamp = 0.0\n",
        "    duration = (float(n) / sample_rate) / 2.0\n",
        "    while offset + n < len(audio):\n",
        "        yield Frame(audio[offset:offset + n], timestamp, duration)\n",
        "        timestamp += duration\n",
        "        offset += n\n",
        "\n",
        "\n",
        "def vad_collector(vad, frames, sample_rate):\n",
        "    is_speech = []\n",
        "    for frame in frames:\n",
        "        is_speech.append(vad.is_speech(frame.bytes, sample_rate))\n",
        "    return is_speech\n",
        "\n",
        "\n",
        "def vad(file):\n",
        "    audio, sample_rate = read_wave(file)\n",
        "    vad = webrtcvad.Vad(2)\n",
        "    frames = frame_generator(10, audio, sample_rate)\n",
        "    frames = list(frames)\n",
        "    segments = vad_collector(vad, frames, sample_rate)\n",
        "    return segments\n",
        "\n",
        "def speech(file):\n",
        "  dummy = 0\n",
        "  data = []\n",
        "  segments = vad(file)\n",
        "  audio, sr = librosa.load(file,sr=8000)\n",
        "  for i in segments:\n",
        "    if i == True:\n",
        "      data.append(audio[dummy:dummy + 480])\n",
        "      dummy = dummy + 480\n",
        "    else:\n",
        "      dummy = dummy + 480\n",
        "  data = np.ravel(np.asarray(data))\n",
        "\n",
        "  return data\n",
        "\n",
        "def fxn(file):\n",
        "  segments = vad(file)\n",
        "  segments = np.asarray(segments)\n",
        "  dummy = 0.01*np.where(segments[:-1] != segments[1:])[0] +.01 \n",
        "  if len(dummy)%2==0:\n",
        "    dummy = dummy\n",
        "  else:\n",
        "    dummy = np.delete(dummy, len(dummy)-1)\n",
        "\n",
        "  voice = dummy.reshape(int(len(dummy)/2),2)\n",
        "  \n",
        "  return voice"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: webrtcvad in /usr/local/lib/python3.7/dist-packages (2.0.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWrP6R8ilaRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9582d8c-5d30-48a2-f575-6429d0005e7b"
      },
      "source": [
        "#Segmentation (Each Segment will have only one Speaker)\n",
        "# %tensorflow_version 1.x\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers.core import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, TimeDistributed, Dropout\n",
        "from keras.layers import LSTM\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(TimeDistributed(Dense(32)))\n",
        "model.add(TimeDistributed(Dense(32)))\n",
        "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
        "\n",
        "model.build(input_shape=(None, 137, 35))\n",
        "model.summary()\n",
        "#Upload the pre-trained model file from Google Drive. Change the Path accordingly.\n",
        "h5_model_file = 'Speaker-Diarization/Model/model_hindi_2.h5'\n",
        "model.load_weights(h5_model_file)\n",
        "\n",
        "\n",
        "def multi_segmentation(file):\n",
        "    frame_size = 2048\n",
        "    frame_shift = 512\n",
        "    y, sr = librosa.load(file,sr=8000)\n",
        "    mfccs = librosa.feature.mfcc(y, sr, n_mfcc=12, hop_length=frame_shift, n_fft=frame_size)\n",
        "    mfcc_delta = librosa.feature.delta(mfccs)\n",
        "    mfcc_delta2 = librosa.feature.delta(mfccs, order=2)\n",
        "    mfcc = mfccs[1:, ]\n",
        "    norm_mfcc = (mfcc - np.mean(mfcc, axis=1, keepdims=True)) / np.std(mfcc, axis=1, keepdims=True)\n",
        "    norm_mfcc_delta = (mfcc_delta - np.mean(mfcc_delta, axis=1, keepdims=True)) / np.std(mfcc_delta, axis=1, keepdims=True)\n",
        "    norm_mfcc_delta2 = (mfcc_delta2 - np.mean(mfcc_delta2, axis=1, keepdims=True)) / np.std(mfcc_delta2, axis=1, keepdims=True)\n",
        "\n",
        "    ac_feature = np.vstack((norm_mfcc, norm_mfcc_delta, norm_mfcc_delta2))\n",
        "    print(ac_feature.shape)\n",
        "\n",
        "    sub_seq_len = int(3.2 * sr / frame_shift)\n",
        "    sub_seq_step = int(0.8 * sr / frame_shift)\n",
        "\n",
        "    def extract_feature():\n",
        "        feature_len = ac_feature.shape[1]\n",
        "        sub_train_x = []\n",
        "        for i in range(0, feature_len-sub_seq_len, sub_seq_step):\n",
        "            sub_seq_x = np.transpose(ac_feature[:, i: i+sub_seq_len])\n",
        "            sub_train_x.append(sub_seq_x[np.newaxis, :, :])\n",
        "        return np.vstack(sub_train_x), feature_len\n",
        "\n",
        "    predict_x, feature_len = extract_feature()\n",
        "    print(predict_x.shape)\n",
        "\n",
        "    predict_y = model.predict(predict_x)\n",
        "    print(predict_y.shape)\n",
        "\n",
        "    score_acc = np.zeros((feature_len, 1))\n",
        "    score_cnt = np.ones((feature_len, 1))\n",
        "\n",
        "    for i in range(predict_y.shape[0]):\n",
        "        for j in range(predict_y.shape[1]):\n",
        "            index = i*sub_seq_step+j\n",
        "            score_acc[index] += predict_y[i, j, 0]\n",
        "            score_cnt[index] += 1\n",
        "\n",
        "    score_norm = score_acc / score_cnt\n",
        "\n",
        "    wStart = 0\n",
        "    wEnd = 200\n",
        "    wGrow = 200\n",
        "    delta = 25\n",
        "\n",
        "    store_cp = []\n",
        "    index = 0\n",
        "    while wEnd < feature_len:\n",
        "        score_seg = score_norm[wStart:wEnd]\n",
        "        max_v = np.max(score_seg)\n",
        "        max_index = np.argmax(score_seg)\n",
        "        index = index + 1\n",
        "        if max_v > 0.5:\n",
        "            temp = wStart + max_index\n",
        "            store_cp.append(temp)\n",
        "            wStart = wStart + max_index + 50\n",
        "            wEnd = wStart + wGrow\n",
        "        else:\n",
        "            wEnd = wEnd + wGrow\n",
        "\n",
        "    seg_point = np.array(store_cp)*frame_shift\n",
        "\n",
        "    plt.figure('speech segmentation plot')\n",
        "    plt.plot(np.arange(0, len(y)) / (float)(sr), y, \"b-\")\n",
        "\n",
        "    for i in range(len(seg_point)):\n",
        "        plt.vlines(seg_point[i] / (float)(sr), -1, 1, colors=\"c\", linestyles=\"dashed\")\n",
        "        plt.vlines(seg_point[i] / (float)(sr), -1, 1, colors=\"r\", linestyles=\"dashed\")\n",
        "    plt.xlabel(\"Time/s\")\n",
        "    plt.ylabel(\"Speech Amp\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "    print(np.asarray(seg_point) / float(sr))\n",
        "    return np.asarray(seg_point) / float(sr)"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_26 (Bidirecti  (None, 137, 256)         167936    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_27 (Bidirecti  (None, 137, 256)         394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " time_distributed_39 (TimeDi  (None, 137, 32)          8224      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_40 (TimeDi  (None, 137, 32)          1056      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_41 (TimeDi  (None, 137, 1)           33        \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 571,489\n",
            "Trainable params: 571,489\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onC8jO7Tl99E"
      },
      "source": [
        "#Re-segmentation (Based on Combining VAD and Segementation Output)\n",
        "def group_intervals(a):\n",
        "    a = a.tolist()\n",
        "    ans = []\n",
        "\n",
        "    curr = None\n",
        "    for x in a:\n",
        "        # no previous interval under consideration\n",
        "        if curr == None:\n",
        "          curr = x\n",
        "        else:\n",
        "            # check if we can merge the intervals\n",
        "            if x[0]-curr[1] < 1:\n",
        "                curr[1] = x[1]\n",
        "            else:\n",
        "            # if we cannot merge, push the current element to ans\n",
        "                ans.append(curr)\n",
        "                curr = x\n",
        "\n",
        "        if curr is not None:\n",
        "            ans.append(curr)\n",
        "\n",
        "    d1 = np.asarray(ans)\n",
        "    d2 = np.unique(d1)\n",
        "    d3 = d2.reshape(int(len(d2)/2),2)\n",
        "    return d3\n",
        "    \n",
        "def spliting(seg,arr):\n",
        "  arr1 = arr.tolist()\n",
        "  temp = arr.copy()\n",
        "  \n",
        "  for i in range(len(seg)-1):\n",
        "    temp1 = float(seg[i])\n",
        "    # print(temp1)\n",
        "    #for j in range(len(arr)-1):\n",
        "    for j in range(len(arr)):\n",
        "      if ((temp1 > arr[j][0]) & (temp1 < arr[j][1])):\n",
        "        arr1[j].insert(-1,(temp1))\n",
        "\n",
        "  #for i in range(len(arr1-1)):\n",
        "  for i in range(len(arr1)):\n",
        "    size=len(arr1[i])\n",
        "    if size>=3:\n",
        "      arr1[i].pop(-2) if arr1[i][-1]-arr1[i][-2]<0.2 else True\n",
        "      \n",
        "  return arr1\n",
        "  \n",
        "def final_reseg(arr):\n",
        "  z=[]\n",
        "  for i in arr:\n",
        "    if len(i)==2:\n",
        "      z.append(i)\n",
        "    else:\n",
        "      temp = len(i)\n",
        "      for j in range(temp-1):\n",
        "        if j!=temp-1:\n",
        "          temp1 = [i[j],i[j+1]-0.01]\n",
        "          z.append(temp1)\n",
        "        elif j==temp-1:\n",
        "          temp1 = [i[j],i[j+1]]\n",
        "          z.append(temp1)\n",
        "  \n",
        "  return np.asarray(z)"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1JdDad7ndpk"
      },
      "source": [
        "#Embedding Extraction\n",
        "import torch\n",
        "import librosa\n",
        "from pyannote.core import Segment\n",
        "\n",
        "def embeddings_(audio_path,resegmented,range):\n",
        "  model_emb = torch.hub.load('pyannote/pyannote-audio', 'emb')\n",
        "  \n",
        "  embedding = model_emb({'audio': audio_path})\n",
        "  for window, emb in embedding:\n",
        "    assert isinstance(window, Segment)\n",
        "    assert isinstance(emb, np.ndarray)\n",
        "\n",
        "  y, sr = librosa.load(audio_path,sr=8000)\n",
        "  myDict={}\n",
        "  myDict['audio'] = audio_path\n",
        "  myDict['duration'] = len(y)/sr\n",
        "  print(resegmented)\n",
        "  data=[]\n",
        "  # count = 0\n",
        "  print(resegmented)\n",
        "  for i in resegmented:\n",
        "    excerpt = Segment(start=i[0], end=i[0]+range)\n",
        "    emb = model_emb.crop(myDict,excerpt)\n",
        "    data.append(emb.T)\n",
        "  data= np.asarray(data)\n",
        "  \n",
        "  return data.reshape(len(data),512)"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc2APlNsom2b"
      },
      "source": [
        "#Clustering (Mean-Shift)\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import MeanShift, SpectralClustering, AgglomerativeClustering\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "scaler = StandardScaler()\n",
        "def clustering(emb):\n",
        "  clusterer = AgglomerativeClustering(n_clusters = 2)\n",
        "  temp = scaler.fit_transform(emb)\n",
        "  # Y = TSNE(n_components=3).fit_transform(temp)\n",
        "  # cluster_ms = MeanShift(bandwidth = 3,max_iter='200',cluster_all=False).fit(Y)\n",
        "  # y_ms = cluster_ms.predict(Y)\n",
        "  y_ms = clusterer.fit_predict(temp)\n",
        "  # clus_centre = cluster_ms.cluster_centers_\n",
        "  # n_speakers = clus_centre.shape[0]\n",
        "  plt.figure\n",
        "  plt.scatter(Y[:,0], Y[:, 1], c=y_ms, s=50, cmap='viridis')\n",
        "  plt.show()\n",
        "\n",
        "  return y_ms, 2"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EjVUubjpB-w"
      },
      "source": [
        "#Generating Hypothesis\n",
        "from pyannote.core import Annotation, Segment\n",
        "def hypothesis_gen(hyp_df):\n",
        "  hyp_records = hyp_df.to_records(index=False)\n",
        "  hyp_rec = list(hyp_records)\n",
        "  hypothesis = Annotation()\n",
        "  for i in range(len(hyp_rec)-1):\n",
        "    hypothesis[Segment(hyp_rec[i][1], hyp_rec[i][2])] = hyp_rec[i][0]\n",
        "\n",
        "  return hypothesis"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKLzU1mVpKyZ"
      },
      "source": [
        "#Diarization \n",
        "from sklearn import preprocessing\n",
        "import pandas as pd\n",
        "def diarization(audiofile):\n",
        "    voice = fxn(audiofile)\n",
        "    segmented = multi_segmentation(audiofile)\n",
        "    gp = group_intervals(voice)\n",
        "    splt = spliting(segmented,gp)\n",
        "    resegmented = final_reseg(splt)\n",
        "    embeddings = embeddings_(audiofile,resegmented,2)\n",
        "    speak_id , n_speakers = clustering(embeddings)\n",
        "    label_list = []\n",
        "    alpha = 'A'\n",
        "    for i in range(0, n_speakers): \n",
        "        label_list.append(alpha) \n",
        "        alpha = chr(ord(alpha) + 1) \n",
        "    lb = preprocessing.LabelEncoder()\n",
        "    print(\"n_speakers = \",n_speakers)\n",
        "    label_hyp = lb.fit(label_list)\n",
        "    print(\"2\")\n",
        "    speaker_id = lb.inverse_transform(speak_id)\n",
        "    print(\"3\")\n",
        "    print(resegmented)\n",
        "    hyp_df = pd.DataFrame({'Speaker_id': speaker_id,'Offset': resegmented[:, 0], 'end': resegmented[:, 1]})\n",
        "    print(\"4\")\n",
        "    result_hypo = hypothesis_gen(hyp_df)  \n",
        "    return segmented, n_speakers, hyp_df, result_hypo"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T17SeN1Hw__b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "0994f4a2-b6c3-45f4-c641-d9987ace849c"
      },
      "source": [
        "#Give the path of audio file for Speaker Diarization (It should be Mono type.)\n",
        "segmented, n_clusters, hyp_df, result_hypo = diarization('issa-basel (1).wav')\n",
        "print(n_clusters)\n",
        "print(hyp_df)\n",
        "hyp_df"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_rate =  8000\n",
            "(35, 822)\n",
            "(65, 50, 35)\n",
            "(65, 50, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.304 46.848]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pyannote_pyannote-audio_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.17  10.294]\n",
            " [10.304 16.52 ]\n",
            " [18.47  51.66 ]]\n",
            "[[ 2.17  10.294]\n",
            " [10.304 16.52 ]\n",
            " [18.47  51.66 ]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-217-5fb27a354bde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Give the path of audio file for Speaker Diarization (It should be Mono type.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msegmented\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyp_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_hypo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiarization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'issa-basel (1).wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhyp_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-205-4a0524faa3e1>\u001b[0m in \u001b[0;36mdiarization\u001b[0;34m(audiofile)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mresegmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_reseg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudiofile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresegmented\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mspeak_id\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mn_speakers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-216-8844b43573ed>\u001b[0m in \u001b[0;36mclustering\u001b[0;34m(emb)\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# n_speakers = clus_centre.shape[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'viridis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMRwTnjJyu7A"
      },
      "source": [
        "#Evaluation (DER)\n",
        "def reference_gen(annotation_path):\n",
        "  df = pd.read_csv(annotation_path)\n",
        "  ref_df = df[df['filename'] == 'Hindi_01']\n",
        "  ref_df = ref_df.assign(end = ref_df.Offset + ref_df.Duration)\n",
        "  ref_df = ref_df[['Speaker_id','Offset','end']]\n",
        "  ref_records = ref_df.to_records(index=False)\n",
        "  ref_rec = list(ref_records)\n",
        "  reference = Annotation()\n",
        "  for i in range(len(ref_rec)-1):\n",
        "    reference[Segment(ref_rec[i][1], ref_rec[i][2])] = ref_rec[i][0]\n",
        "\n",
        "  return reference, ref_df"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooGFwg2cx96R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "80ef42cc-14a0-41a3-f01f-9d40b5fb7032"
      },
      "source": [
        "#Give the path for Annotations File of Audio for calculating DER.\n",
        "reference, ref_df = reference_gen('/content/drive/My Drive/SRU/hindi_annotations1.csv')\n",
        "#Visualization (Comparing Between Ground Truth and Hypothesis)\n",
        "reference"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-208-574dabe66918>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Give the path for Annotations File of Audio for calculating DER.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mreference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/SRU/hindi_annotations1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#Visualization (Comparing Between Ground Truth and Hypothesis)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-207-0e6ca352aea7>\u001b[0m in \u001b[0;36mreference_gen\u001b[0;34m(annotation_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Evaluation (DER)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreference_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mref_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Hindi_01'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mref_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mref_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mref_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDuration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/SRU/hindi_annotations1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L85ga_d9U4s"
      },
      "source": [
        "result_hypo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eWYkbK8v1Bg"
      },
      "source": [
        "from pyannote.metrics.diarization import DiarizationErrorRate\n",
        "from pyannote.metrics.diarization import DiarizationPurity\n",
        "from pyannote.metrics.diarization import DiarizationCoverage\n",
        "#Upload the annotation file from Google Drive. Change the Path accordingly.\n",
        "result_ref, ref_df = reference_gen('/content/drive/My Drive/SRU/hindi_annotations1.csv')\n",
        "diarizationErrorRate = DiarizationErrorRate()\n",
        "print(\"DER = {0:.3f}\".format(diarizationErrorRate(result_ref, result_hypo)))\n",
        "#To Evaluate particular Segment of audio-file.\n",
        "diarizationErrorRate(result_ref, result_hypo, detailed=True, uem=Segment(0, 40))\n",
        "#Purity \n",
        "purity = DiarizationPurity()\n",
        "print(\"Purity = {0:.3f}\".format(purity(result_ref, result_hypo, uem=Segment(0, 40))))\n",
        "#Coverage\n",
        "coverage = DiarizationCoverage()\n",
        "print(\"Coverage = {0:.3f}\".format(coverage(result_ref, result_hypo, uem=Segment(0, 40))))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}